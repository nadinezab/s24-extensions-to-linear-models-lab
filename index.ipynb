{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions to Linear Models - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, you'll practice many concepts you have learned so far, from adding interactions and polynomials to your model to AIC and BIC!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You will be able to:\n",
    "- Build a linear regression model with interactions and polynomial features \n",
    "- Use AIC and BIC to select the best value for the regularization parameter \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at a baseline boston housing data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import the Boston housing dataset \n",
    "- Split the data into target (`y`) and predictors (`X`) -- ensure these both are DataFrames \n",
    "- Scale all the predictors using `scale`. Convert these scaled features into a DataFrame \n",
    "- Build at a baseline model using *scaled variables* as predictors. Use 5-fold cross-validation (set `random_state` to 1) and use the $R^2$ score to evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Boston\n",
    "boston = load_boston()\n",
    "\n",
    "# Define DataFrames for X and y\n",
    "y = pd.DataFrame(boston.target, columns = [\"target\"])\n",
    "X = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "\n",
    "# Scale predictors using scale\n",
    "X_scaled = scale(X)\n",
    "\n",
    "# Convert scaled features back to DataFrame\n",
    "X_scaled = pd.DataFrame(X_scaled, columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7176778617934925"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create linreg instance\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# Define crossval\n",
    "crossval = KFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "\n",
    "# Cross val score\n",
    "cv5 = cross_val_score(linreg, X_scaled, y, scoring = 'r2', cv = crossval)\n",
    "\n",
    "# Get mean score\n",
    "base_r_2 = np.mean(cv5)\n",
    "base_r_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include interactions\n",
    "\n",
    "Look at all the possible combinations of variables for interactions by adding interactions one by one to the baseline model. Next, evaluate that model using 5-fold cross-validation and store the $R^2$ to compare it with the baseline model.\n",
    "\n",
    "Print the 7 most important interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "from itertools import combinations\n",
    "combs = list(combinations(X_scaled.columns,2))\n",
    "len(combs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CRIM', 'ZN'),\n",
       " ('CRIM', 'INDUS'),\n",
       " ('CRIM', 'CHAS'),\n",
       " ('CRIM', 'NOX'),\n",
       " ('CRIM', 'RM')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions = []\n",
    "df = X_scaled.copy()\n",
    "for pair in combs:\n",
    "    df['interacting_term'] = df[pair[0]]*df[pair[1]]\n",
    "    score = np.mean(cross_val_score(linreg, df, y, scoring = 'r2', cv = crossval))\n",
    "    if score > base_r_2:\n",
    "        interactions.append((pair[0],pair[1], round(score,4)))\n",
    "len(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('RM', 'LSTAT', 0.7832),\n",
       " ('RM', 'TAX', 0.7753),\n",
       " ('RM', 'RAD', 0.7701),\n",
       " ('RM', 'PTRATIO', 0.7636),\n",
       " ('INDUS', 'RM', 0.7566),\n",
       " ('NOX', 'RM', 0.7461),\n",
       " ('RM', 'AGE', 0.7421)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_interactions = sorted(interactions,key=lambda item: item[2], reverse = True)\n",
    "top_interactions[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to include the 7 most important interactions in your data set by adding 7 columns. Name the columns \"var1_var2\" with var1 and var2 the two variables in the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "df_with_inter = X_scaled.copy()\n",
    "top_7_interactions = top_interactions[:7]\n",
    "for interaction in top_7_interactions:\n",
    "    var1 = interaction[0]\n",
    "    var2 = interaction[1]\n",
    "    df_with_inter[f\"{var1}_{var2}\"] = df_with_inter[var1]*df_with_inter[var2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RM_LSTAT</th>\n",
       "      <th>RM_TAX</th>\n",
       "      <th>RM_RAD</th>\n",
       "      <th>RM_PTRATIO</th>\n",
       "      <th>INDUS_RM</th>\n",
       "      <th>NOX_RM</th>\n",
       "      <th>RM_AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "      <td>-0.444930</td>\n",
       "      <td>-0.275757</td>\n",
       "      <td>-0.406574</td>\n",
       "      <td>-0.603547</td>\n",
       "      <td>-0.532772</td>\n",
       "      <td>-0.059659</td>\n",
       "      <td>-0.049646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "      <td>-0.095668</td>\n",
       "      <td>-0.191813</td>\n",
       "      <td>-0.168607</td>\n",
       "      <td>-0.058883</td>\n",
       "      <td>-0.115279</td>\n",
       "      <td>-0.143814</td>\n",
       "      <td>0.071331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "      <td>-1.550451</td>\n",
       "      <td>-1.266461</td>\n",
       "      <td>-1.113245</td>\n",
       "      <td>-0.388783</td>\n",
       "      <td>-0.761138</td>\n",
       "      <td>-0.949544</td>\n",
       "      <td>-0.340960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "      <td>-1.383713</td>\n",
       "      <td>-1.124148</td>\n",
       "      <td>-0.765197</td>\n",
       "      <td>0.114875</td>\n",
       "      <td>-1.328183</td>\n",
       "      <td>-0.848901</td>\n",
       "      <td>-0.823092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "      <td>-1.261136</td>\n",
       "      <td>-1.358947</td>\n",
       "      <td>-0.925023</td>\n",
       "      <td>0.138869</td>\n",
       "      <td>-1.605599</td>\n",
       "      <td>-1.026210</td>\n",
       "      <td>-0.628023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "\n",
       "        DIS       RAD       TAX   PTRATIO         B     LSTAT  RM_LSTAT  \\\n",
       "0  0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562 -0.444930   \n",
       "1  0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439 -0.095668   \n",
       "2  0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727 -1.550451   \n",
       "3  1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517 -1.383713   \n",
       "4  1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501 -1.261136   \n",
       "\n",
       "     RM_TAX    RM_RAD  RM_PTRATIO  INDUS_RM    NOX_RM    RM_AGE  \n",
       "0 -0.275757 -0.406574   -0.603547 -0.532772 -0.059659 -0.049646  \n",
       "1 -0.191813 -0.168607   -0.058883 -0.115279 -0.143814  0.071331  \n",
       "2 -1.266461 -1.113245   -0.388783 -0.761138 -0.949544 -0.340960  \n",
       "3 -1.124148 -0.765197    0.114875 -1.328183 -0.848901 -0.823092  \n",
       "4 -1.358947 -0.925023    0.138869 -1.605599 -1.026210 -0.628023  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_inter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try polynomials of degrees 2, 3, and 4 for each variable, in a similar way you did for interactions (by looking at your baseline model and seeing how $R^2$ increases). Do understand that when going for a polynomial of 4, the particular column is raised to the power of 2 and 3 as well in other terms. We only want to include \"pure\" polynomials, so make sure no interactions are included. We want the result to return a list that contain tuples of the form:\n",
    "\n",
    "`(var_name, degree, R2)`, so eg. `('DIS', 3, 0.732)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "polynomials = []\n",
    "degrees = [2,3,4]\n",
    "\n",
    "for feature in df.columns:\n",
    "    for degree in degrees:\n",
    "        df = X_scaled.copy()   \n",
    "        poly = PolynomialFeatures(degree, include_bias = False)\n",
    "        X_transformed = poly.fit_transform(X[[feature]])\n",
    "        df = pd.concat([df.drop(feature, axis=1),pd.DataFrame(X_transformed)], axis=1)\n",
    "        score = np.mean(cross_val_score(linreg, df, y, scoring='r2', cv=crossval))\n",
    "        if score > base_r_2: \n",
    "            polynomials.append((feature, degree, round(score, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('RM', 4, 0.8),\n",
       " ('RM', 2, 0.782),\n",
       " ('LSTAT', 4, 0.782),\n",
       " ('RM', 3, 0.781),\n",
       " ('LSTAT', 3, 0.774),\n",
       " ('LSTAT', 2, 0.772),\n",
       " ('DIS', 3, 0.737),\n",
       " ('DIS', 2, 0.732),\n",
       " ('DIS', 4, 0.731),\n",
       " ('TAX', 4, 0.724)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_polynomials = sorted(polynomials, key = lambda item: item[2], reverse = True)[:10]\n",
    "top_polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each variable, print out the maximum R2 possible when including Polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ZN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>INDUS</td>\n",
       "      <td>4</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NOX</td>\n",
       "      <td>4</td>\n",
       "      <td>0.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RM</td>\n",
       "      <td>4</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AGE</td>\n",
       "      <td>4</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DIS</td>\n",
       "      <td>4</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RAD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TAX</td>\n",
       "      <td>4</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>3</td>\n",
       "      <td>0.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LSTAT</td>\n",
       "      <td>4</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         1      2\n",
       "0                \n",
       "ZN       4  0.723\n",
       "INDUS    4  0.723\n",
       "NOX      4  0.721\n",
       "RM       4  0.800\n",
       "AGE      4  0.722\n",
       "DIS      4  0.737\n",
       "RAD      4  0.720\n",
       "TAX      4  0.724\n",
       "PTRATIO  3  0.721\n",
       "B        4  0.720\n",
       "LSTAT    4  0.782"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "poly_df = pd.DataFrame(polynomials)\n",
    "poly_df.groupby([0], sort = False)[[1,2]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which two variables seem to benefit most from adding polynomial terms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RM and LSTAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Polynomials for the two features that seem to benefit the most, as in have the best R squared compared to the baseline model. For each of the two features, raise to the Polynomial that generates the best result. Make sure to start from the data set `df_inter` so the final data set has both interactions and polynomials in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "cols = ['RM', 'LSTAT']\n",
    "\n",
    "for col in cols:\n",
    "    poly = PolynomialFeatures(4, include_bias = False)\n",
    "    X_transformed = poly.fit_transform(X[[col]])\n",
    "    colnames = [col, col+\"_2\", col+\"_3\", col+\"_4\"]\n",
    "    df_with_inter = pd.concat([df_with_inter.drop(col, axis = 1), pd.DataFrame(X_transformed, columns = colnames)], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out your final data set and make sure that your interaction terms as well as your polynomial terms are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>NOX_RM</th>\n",
       "      <th>RM_AGE</th>\n",
       "      <th>RM</th>\n",
       "      <th>RM_2</th>\n",
       "      <th>RM_3</th>\n",
       "      <th>RM_4</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>LSTAT_2</th>\n",
       "      <th>LSTAT_3</th>\n",
       "      <th>LSTAT_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059659</td>\n",
       "      <td>-0.049646</td>\n",
       "      <td>6.575</td>\n",
       "      <td>43.230625</td>\n",
       "      <td>284.241359</td>\n",
       "      <td>1868.886938</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.8004</td>\n",
       "      <td>123.505992</td>\n",
       "      <td>615.059840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143814</td>\n",
       "      <td>0.071331</td>\n",
       "      <td>6.421</td>\n",
       "      <td>41.229241</td>\n",
       "      <td>264.732956</td>\n",
       "      <td>1699.850313</td>\n",
       "      <td>9.14</td>\n",
       "      <td>83.5396</td>\n",
       "      <td>763.551944</td>\n",
       "      <td>6978.864768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.949544</td>\n",
       "      <td>-0.340960</td>\n",
       "      <td>7.185</td>\n",
       "      <td>51.624225</td>\n",
       "      <td>370.920057</td>\n",
       "      <td>2665.060607</td>\n",
       "      <td>4.03</td>\n",
       "      <td>16.2409</td>\n",
       "      <td>65.450827</td>\n",
       "      <td>263.766833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.848901</td>\n",
       "      <td>-0.823092</td>\n",
       "      <td>6.998</td>\n",
       "      <td>48.972004</td>\n",
       "      <td>342.706084</td>\n",
       "      <td>2398.257176</td>\n",
       "      <td>2.94</td>\n",
       "      <td>8.6436</td>\n",
       "      <td>25.412184</td>\n",
       "      <td>74.711821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.026210</td>\n",
       "      <td>-0.628023</td>\n",
       "      <td>7.147</td>\n",
       "      <td>51.079609</td>\n",
       "      <td>365.065966</td>\n",
       "      <td>2609.126456</td>\n",
       "      <td>5.33</td>\n",
       "      <td>28.4089</td>\n",
       "      <td>151.419437</td>\n",
       "      <td>807.065599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX       AGE       DIS  \\\n",
       "0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217 -0.120013  0.140214   \n",
       "1 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.367166  0.557160   \n",
       "2 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262 -0.265812  0.557160   \n",
       "3 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284 -0.809889  1.077737   \n",
       "4 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284 -0.511180  1.077737   \n",
       "\n",
       "        RAD       TAX   PTRATIO  ...    NOX_RM    RM_AGE     RM       RM_2  \\\n",
       "0 -0.982843 -0.666608 -1.459000  ... -0.059659 -0.049646  6.575  43.230625   \n",
       "1 -0.867883 -0.987329 -0.303094  ... -0.143814  0.071331  6.421  41.229241   \n",
       "2 -0.867883 -0.987329 -0.303094  ... -0.949544 -0.340960  7.185  51.624225   \n",
       "3 -0.752922 -1.106115  0.113032  ... -0.848901 -0.823092  6.998  48.972004   \n",
       "4 -0.752922 -1.106115  0.113032  ... -1.026210 -0.628023  7.147  51.079609   \n",
       "\n",
       "         RM_3         RM_4  LSTAT  LSTAT_2     LSTAT_3      LSTAT_4  \n",
       "0  284.241359  1868.886938   4.98  24.8004  123.505992   615.059840  \n",
       "1  264.732956  1699.850313   9.14  83.5396  763.551944  6978.864768  \n",
       "2  370.920057  2665.060607   4.03  16.2409   65.450827   263.766833  \n",
       "3  342.706084  2398.257176   2.94   8.6436   25.412184    74.711821  \n",
       "4  365.065966  2609.126456   5.33  28.4089  151.419437   807.065599  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "df_with_inter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the R-squared of the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8061549447222885"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "r_2 = np.mean(cross_val_score(linreg, df_with_inter, y, scoring = 'r2', cv = crossval))\n",
    "r_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best Lasso regularization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You learned that when using Lasso regularization, your coefficients shrink to 0 when using a higher regularization parameter. Now the question is which value we should choose for the regularization parameter. \n",
    "\n",
    "This is where the AIC and BIC come in handy! We'll use both criteria in what follows and perform cross-validation to select an optimal value of the regularization parameter $alpha$ of the Lasso estimator.\n",
    "\n",
    "Read the page here: https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html and create a similar plot as the first one listed on the page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LassoCV, LassoLarsCV, LassoLarsIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006693959229882091"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here \n",
    "\n",
    "model_bic = LassoLarsIC(criterion='bic')\n",
    "model_bic.fit(df_with_inter, y)\n",
    "alpha_bic_ = model_bic.alpha_\n",
    "\n",
    "model_aic = LassoLarsIC(criterion='aic')\n",
    "model_aic.fit(X, y)\n",
    "alpha_aic_ = model_aic.alpha_\n",
    "alpha_aic_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Information-criterion for model selection')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "EPSILON = 1e-4\n",
    "\n",
    "def plot_ic_criterion(model, name, color):\n",
    "    criterion_ = model.criterion_\n",
    "    plt.semilogx(model.alphas_ + EPSILON, criterion_, '--', color=color,\n",
    "                 linewidth=3, label='%s criterion' % name)\n",
    "    plt.axvline(model.alpha_ + EPSILON, color=color, linewidth=3,\n",
    "                label='alpha: %s estimate' % name)\n",
    "    plt.xlabel(r'$\\alpha$')\n",
    "    plt.ylabel('criterion')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plot_ic_criterion(model_aic, 'AIC', 'b')\n",
    "plot_ic_criterion(model_bic, 'BIC', 'r')\n",
    "plt.legend()\n",
    "plt.title('Information-criterion for model selection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the final result\n",
    "\n",
    "Finally, use the best value for the regularization parameter according to AIC and BIC, and compare R-squared and MSE using train-test split. Compare with the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.7168057552393374\n",
      "Test r^2: 0.7789410172622857\n",
      "Training MSE: 22.477983821877896\n",
      "Test MSE: 21.897765396049497\n"
     ]
    }
   ],
   "source": [
    "# Split X_scaled and y into training and test sets\n",
    "# Set random_state to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state = 1)\n",
    "\n",
    "# Code for baseline model\n",
    "linreg_all = LinearRegression()\n",
    "linreg_all.fit(X_train, y_train)\n",
    "\n",
    "# Print R2 and MSE\n",
    "print('Training r^2:', linreg_all.score(X_train, y_train))\n",
    "print('Test r^2:', linreg_all.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, linreg_all.predict(X_train)))\n",
    "print('Test MSE:', mean_squared_error(y_test, linreg_all.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.816342557720897\n",
      "Test r^2: 0.8613029348409235\n",
      "Training MSE: 14.577446726737255\n",
      "Test MSE: 13.739119561486552\n"
     ]
    }
   ],
   "source": [
    "# Split df_inter and y into training and test sets\n",
    "# Set random_state to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_with_inter, y, random_state = 1)\n",
    "\n",
    "# Code for lasso with alpha from AIC\n",
    "lasso = Lasso(alpha = alpha_aic_ )\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Print R2 and MSE\n",
    "print('Training r^2:', lasso.score(X_train, y_train))\n",
    "print('Test r^2:', lasso.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, lasso.predict(X_train)))\n",
    "print('Test MSE:', mean_squared_error(y_test, lasso.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.8153275121120587\n",
      "Test r^2: 0.8607308704287129\n",
      "Training MSE: 14.658013967053952\n",
      "Test MSE: 13.795787388936384\n"
     ]
    }
   ],
   "source": [
    "# Code for lasso with alpha from BIC\n",
    "lasso = Lasso(alpha = alpha_bic_)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Print R2 and MSE\n",
    "print('Training r^2:', lasso.score(X_train, y_train))\n",
    "print('Test r^2:', lasso.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, lasso.predict(X_train)))\n",
    "print('Test MSE:', mean_squared_error(y_test, lasso.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level up (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Lasso path\n",
    "\n",
    "From this section, you know that when using lasso, more parameters shrink to zero as your regularization parameter goes up. In Scikit-learn there is a function `lasso_path()` which visualizes the shrinkage of the coefficients while $alpha$ changes. Try this out yourself!\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIC and BIC for subset selection\n",
    "This notebook shows how you can use AIC and BIC purely for feature selection. Try this code out on our Boston housing data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xavierbourretsicotte.github.io/subset_selection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now know how to create better linear models and how to use AIC and BIC for both feature selection and to optimize your regularization parameter when performing Ridge and Lasso. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
